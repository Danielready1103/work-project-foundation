{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54166f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# 設定列和欄的寬度\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "show=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = {\n",
    "    '國內股票開放型指數型':'ET000001',\n",
    "    '國內股票開放型科技類':'ET001001',\n",
    "    '國內股票開放型中小型':'ET001004',\n",
    "    '國內股票開放型價值型':'ET001007',\n",
    "    '跨國投資股票型區域型':'ET003002'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914e8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(text, l=3):\n",
    "    if l <= show:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f103e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_and_select(data_dict):\n",
    "    while 1:\n",
    "        for i, item in enumerate(data_dict.keys()):\n",
    "            pprint(f\"{i+1:>2}. {item}\", l=0)\n",
    "        sel = input(\"Please select: \")\n",
    "        if sel.isdigit() and 0 < int(sel) <= len(data_dict):\n",
    "            sel = int(sel) - 1\n",
    "            break\n",
    "        else:\n",
    "            pprint('Wrong input!', l=0)\n",
    "        \n",
    "    return list(data_dict.keys())[sel], list(data_dict.values())[sel]\n",
    "\n",
    "def select_type():\n",
    "    selected_item, item_value = display_and_select(item_dict)\n",
    "   \n",
    "    pprint(f\"Selected: {selected_item}\", l=1)\n",
    "    url = f'https://www.moneydj.com/funddj/ya/yp401000.djhtm?A={item_value}&B=901'\n",
    "    pprint(url, l=1)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17cce715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fatch_fund_url(url):\n",
    "    pprint(f\"Fetching find data...\", l=0)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        pprint(f\"Fatch_fund_url() return code: {response.status_code}\", l=0)\n",
    "    response.encoding = 'big5'\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    target_table = soup.find(\"table\", id=\"oMainTable\")\n",
    "    \n",
    "    hyperlinks = []\n",
    "    for row in target_table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        if cells:\n",
    "            fund_name_cell = cells[1]  \n",
    "            link = fund_name_cell.find(\"a\")\n",
    "            if link:\n",
    "                hyperlinks.append([link.text, link[\"href\"].split('?a=')[-1]])\n",
    "                \n",
    "    return hyperlinks\n",
    "# print(hyperlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f979acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n在進行爬蟲時，爬取\"依持有類股\"的表格時遇到多的問題，一方面是要定位出我需要的表格，\\n另一方面是總共三種表格之中這個表格的class與前兩種不同，且中間還多了一個圓餅圖，\\n故在爬取時多了一些針對性的處理與判斷，未來網頁要是有做修改，那CODE也必須跟個做調整\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_fund_coutent(fund_name, url):\n",
    "    # url = 'https://www.moneydj.com/funddj/ya/yp401000.djhtm?A=ET000001&B=901'\n",
    "    # url = 'https://www.moneydj.com/funddj/yp/yp013000.djhtm?a=AC0056'\n",
    "    fund_id = url.split('=')[-1]\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        pprint(f\"Return code: {response.status_code}\", l=0)\n",
    "    response.encoding = 'big5'\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    all_table = soup.find_all('table')\n",
    "\n",
    "    for table_idx, table in enumerate(all_table):\n",
    "        wanted = False\n",
    "        has_data = True\n",
    "        table_name = ''\n",
    "        for td in table.find_all('td'):\n",
    "            if '基金投資分佈' in td.text:\n",
    "                table_name = td.text.strip()\n",
    "                wanted = True\n",
    "            if '無資料'in td.text:\n",
    "                has_data = False\n",
    "                pprint(f\"{table_name} {td.text}\", l=3)\n",
    "                break\n",
    "\n",
    "        if wanted and has_data:\n",
    "            pprint(table, l=3)\n",
    "            pprint(f'Found {table_name}', l=3)\n",
    "\n",
    "            headers = [header.text for header in table.find_all(\"td\", class_='t2c1')]\n",
    "            headers +=  [header.text for header in table.find_all(\"td\", class_='t2')]\n",
    "            pprint(headers, l=3)\n",
    "\n",
    "            def make_table(fund_id, fund_name, type_, content):  \n",
    "                rows = content.find_all(\"tr\")\n",
    "                data = [[col.text.strip() for col in row.find_all(\"td\")] for row in rows[1:]]\n",
    "\n",
    "                df = pd.DataFrame(data, columns=headers)\n",
    "                df_list.append(df)\n",
    "                filename = f\"{fund_id}_{fund_name}_{type_}.csv\"\n",
    "                pprint(f\"Save {filename}.\", l=1)\n",
    "                df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "            for clas in ['t01', 't03']:\n",
    "                sub_table = table.find('table', class_=clas)\n",
    "                if not sub_table:\n",
    "                    continue\n",
    "                pprint(f\"{table_name}, {len(sub_table)}\", l=3)\n",
    "                if not sub_table:\n",
    "                    pprint(f\"{fund_id} {table_name} NO list table!\", l=1)\n",
    "                    break\n",
    "                if len(sub_table)>3 :\n",
    "                    make_table(fund_id, fund_name, table_name, sub_table)\n",
    "                    break\n",
    "            else:\n",
    "                pprint(f\"{table_name} 無資料\", l=3)\n",
    "                    \n",
    "#     print(df_list)\n",
    "'''\n",
    "在進行爬蟲時，爬取\"依持有類股\"的表格時遇到多的問題，一方面是要定位出我需要的表格，\n",
    "另一方面是總共三種表格之中這個表格的class與前兩種不同，且中間還多了一個圓餅圖，\n",
    "故在爬取時多了一些針對性的處理與判斷，未來網頁要是有做修改，那CODE也必須跟個做調整\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861ee06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_fund_class():\n",
    "    type_url = select_type()\n",
    "    fund_url_list = fatch_fund_url(type_url)\n",
    "    pprint(f\"Funds: {len(fund_url_list)}\", l=0)\n",
    "    if len(fund_url_list) >30:\n",
    "        sel = input(\"Go on to fetch for large files? (y/n)\")\n",
    "        if sel.lower() != 'y':\n",
    "            print('Canceld')\n",
    "            return False\n",
    "    base_link = 'https://www.moneydj.com/funddj/yp/yp013000.djhtm?a='\n",
    "    for j, i in enumerate(fund_url_list):\n",
    "        content_link = base_link+i[1]\n",
    "        pprint(f\"{j:>3}. {i[0]}: \\n\\t{content_link}\", l=1)\n",
    "        fetch_fund_coutent(i[0], content_link)\n",
    "    return True\n",
    "        \n",
    "# fetch_fund_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca349006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n在資料合併時是相對比較難處理的，因為每個基金的持股分類csv檔內容中有的欄位並不相同，因此以pd.concat來做合併是很重要的方法，\\n之後再將ID與名稱映射回合併的df，再把NaN的值填為零，就可以進行linear_kernel的計算。\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_files():\n",
    "    pprint(f\"Merging files...\", l=0)\n",
    "    file_paths = glob.glob('*(依持有類股).csv')\n",
    "    \n",
    "    # Initialize an empty dataframe for concatenation\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each file, read the content, add 'Fund_ID' and 'Fund_name' columns and concatenate\n",
    "    for file_path in file_paths:\n",
    "        fund_id = file_path.split('/')[-1].split('_')[0]  # Extract Fund_ID from file name\n",
    "        fund_name = file_path.split('/')[-1].split('_')[1]\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        temp_df['Fund_ID'] = fund_id\n",
    "        temp_df['Fund_name'] = fund_name\n",
    "        merged_df = pd.concat([merged_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Create a mapping from Fund_ID to Fund_name before grouping\n",
    "    fund_name_mapping = merged_df[['Fund_ID', 'Fund_name']].drop_duplicates().set_index('Fund_ID').to_dict()['Fund_name']\n",
    "\n",
    "    # Drop the '投資金額(以萬元為單位)' column\n",
    "    merged_df.drop(columns=['投資金額(以萬元為單位)'], inplace=True)\n",
    "    \n",
    "    # If '比例(%)' column is of object type (possibly string), then remove commas\n",
    "    if merged_df['比例(%)'].dtype == 'object':\n",
    "        merged_df['比例(%)'] = pd.to_numeric(merged_df['比例(%)'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "    # Group by 'Fund_ID' and '名稱' and sum the '比例(%)' values\n",
    "    merged_df = merged_df.groupby(['Fund_ID', '名稱']).sum(numeric_only=True).reset_index()\n",
    "\n",
    "    # Pivot the table\n",
    "    pivoted_df = merged_df.pivot(index='Fund_ID', columns='名稱', values='比例(%)')\n",
    "    pivoted_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Add Fund_name column using the mapping\n",
    "    pivoted_df['Fund_name'] = pivoted_df['Fund_ID'].map(fund_name_mapping)\n",
    "    \n",
    "    # Reorder columns\n",
    "    columns_order = ['Fund_ID', 'Fund_name'] + [col for col in pivoted_df if col not in ['Fund_ID', 'Fund_name']]\n",
    "    pivoted_df = pivoted_df[columns_order]\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    pivoted_df.fillna('0', inplace=True)\n",
    "    \n",
    "    pivoted_df.to_csv('Total.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return pivoted_df\n",
    "\n",
    "# merge_files()\n",
    "\n",
    "\n",
    "'''\n",
    "在資料合併時是相對比較難處理的，因為每個基金的持股分類csv檔內容中有的欄位並不相同，因此以pd.concat來做合併是很重要的方法，\n",
    "之後再將ID與名稱映射回合併的df，再把NaN的值填為零，就可以進行linear_kernel的計算。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81fbf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n最後在呈現結果時思考應該要列出推薦的五支基金各自的前五大持股分類，還是要五支基金綜合的前五大持股分類的各自比例，\\n故在推薦部分做了兩種，但是出乎意料的是直接撈出各自的持股比例來呈現反而是比較難處理的，\\n因為要從各個欄位擷取出前五大，再整合至一個欄位之中需要比較多的特別處理。\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_funds_with_detailed_distribution(df, fund_input, n_recommendations=5, n_largest=5):\n",
    "    \"\"\"\n",
    "    Recommend similar funds based on the provided fund ID or fund name and also show their top 5 investment distribution \n",
    "    percentages in descending order.\n",
    "    \n",
    "    Parameters:\n",
    "    - fund_input: Fund ID or Fund name for which recommendations are to be made.\n",
    "    - n_recommendations: Number of top similar funds to recommend. Default is 5.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing recommended funds, their similarity scores, and detailed top 5 investment distribution.\n",
    "    \"\"\"\n",
    "    investment_data = df.iloc[:, 2:]\n",
    "    similarity_matrix = linear_kernel(investment_data, investment_data)\n",
    "\n",
    "    # Find the index of the given fund\n",
    "    idx = df[df['Fund_ID'] == fund_input].index[0]\n",
    "    \n",
    "    input_fund_distribution = df.iloc[idx, 2:].sort_values(ascending=False)\n",
    "#     print(\"Top 5 investment categories for the input fund:\")\n",
    "    print(f\"Top 5 investment categories for the fund <{fund_input}>:\")\n",
    "    print(input_fund_distribution.head(n_largest))\n",
    "    \n",
    "    # Get the pairwise similarity scores for the given fund\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    \n",
    "    # Sort the funds based on similarity scores\n",
    "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores for the top n similar funds\n",
    "    top_scores = sorted_scores[1:n_recommendations+1]\n",
    "    \n",
    "    # Get the fund indices for the top n similar funds\n",
    "    fund_indices = [i[0] for i in top_scores]\n",
    "    \n",
    "    # Create the recommendations DataFrame\n",
    "    recommended_funds = df.iloc[fund_indices].copy()\n",
    "    recommended_funds['Similarity_Score'] = [round(i[1],2) for i in top_scores]\n",
    "    \n",
    "    # Get the top 5 investment categories and their percentages for each recommended fund\n",
    "    investment_cols = df.columns[2:-1]\n",
    "    recommended_funds['Top_Investments'] = recommended_funds[investment_cols].apply(\n",
    "        lambda row: \", \".join([f\"{col} ({row[col]:.2f}%)\" for col in row.nlargest(n_largest).index]), axis=1)\n",
    "    \n",
    "    final = recommended_funds[['Fund_ID', 'Fund_name', 'Similarity_Score', 'Top_Investments']].copy()\n",
    "    final.to_csv('recommand.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return final\n",
    "\n",
    "'''\n",
    "最後在呈現結果時思考應該要列出推薦的五支基金各自的前五大持股分類，還是要五支基金綜合的前五大持股分類的各自比例，\n",
    "故在推薦部分做了兩種，但是出乎意料的是直接撈出各自的持股比例來呈現反而是比較難處理的，\n",
    "因為要從各個欄位擷取出前五大，再整合至一個欄位之中需要比較多的特別處理。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fc0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_funds_with_combined_distribution(df, fund_input, n_recommendations=5, n_largest=5):\n",
    "    \"\"\"\n",
    "    Recommend similar funds based on the provided fund ID or fund name and also show their investment distribution \n",
    "    percentages in the top 5 investment categories of the combined recommended funds.\n",
    "    \"\"\"\n",
    "    \n",
    "    investment_data = df.iloc[:, 2:]\n",
    "    similarity_matrix = linear_kernel(investment_data, investment_data)\n",
    "\n",
    "    # Find the index of the given fund\n",
    "    idx = df[df['Fund_ID'] == fund_input].index[0]\n",
    "    \n",
    "    input_fund_distribution = df.iloc[idx, 2:].sort_values(ascending=False)\n",
    "    print(f\"Top 5 investment categories for the fund <{fund_input}>:\")\n",
    "    print(input_fund_distribution.head(n_largest))\n",
    " \n",
    "    # Get the pairwise similarity scores for the given fund\n",
    "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    \n",
    "    # Sort the funds based on similarity scores and get the top n similar funds\n",
    "    top_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:n_recommendations+1]\n",
    "    \n",
    "    # Get the fund indices for the top n similar funds\n",
    "    fund_indices = [i[0] for i in top_scores]\n",
    "    \n",
    "    # Create the recommendations DataFrame\n",
    "    recommended_funds = df.iloc[fund_indices].copy()\n",
    "    recommended_funds['Similarity_Score'] = [round(i[1],2) for i in top_scores]\n",
    "    \n",
    "    # Calculate the combined investment distribution for all recommended funds\n",
    "    combined_distribution = recommended_funds.iloc[:, 2:-1].sum()\n",
    "    \n",
    "    # Get the top 5 investment categories from the combined distribution\n",
    "    top_investments = combined_distribution.nlargest(n_largest).index.tolist()\n",
    "    \n",
    "    final = recommended_funds[['Fund_ID', 'Fund_name', 'Similarity_Score'] + top_investments]\n",
    "    final.to_csv('recommend_combined.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a16afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggesting(type_=1):\n",
    "    # Load the CSV data\n",
    "    df = pd.read_csv('Total.csv')\n",
    "\n",
    "    id_list = list(df['Fund_ID'])\n",
    "    name_list = list(df['Fund_name'])\n",
    "\n",
    "    while 1:\n",
    "        for i, j in enumerate(zip(id_list, name_list)):\n",
    "            print(f\"{i+1:>2}. {j[0]:>8}: {j[1]}\")\n",
    "        sel = input(\"Please select: \")\n",
    "        if sel.isdigit() and 0 < int(sel) <= len(id_list):\n",
    "            sel = int(sel) - 1\n",
    "            break\n",
    "        else:\n",
    "            print('Wrong input!')\n",
    "\n",
    "    pprint(f\"Selection: {id_list[sel]} - {name_list[sel]}\", l=0)\n",
    "    if type_==1 :\n",
    "        recommendations = recommend_funds_with_detailed_distribution(df, id_list[sel])\n",
    "        \n",
    "    else:\n",
    "        recommendations = recommend_funds_with_combined_distribution(df, id_list[sel])\n",
    "        \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e589eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv():\n",
    "    csv_files = glob.glob('*.csv')\n",
    "    if len(csv_files) == 0:\n",
    "        return\n",
    "    pprint('Clean CSV files...', l=1)\n",
    "    for file in tqdm(csv_files, desc=\"刪除檔案\"):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            pprint(f\"已刪除檔案: {file}\", l=1)\n",
    "        except Exception as e:\n",
    "            print(f\"刪除檔案 {file} 時出錯: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ac2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e90efbf897420688fdf2f0156e13ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "刪除檔案:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 國內股票開放型指數型\n",
      " 2. 國內股票開放型科技類\n",
      " 3. 國內股票開放型中小型\n",
      " 4. 國內股票開放型價值型\n",
      " 5. 跨國投資股票型區域型\n"
     ]
    }
   ],
   "source": [
    "show=0 # 0~2 調整顯示訊息\n",
    "sugg_type=0 # 1,0 調整推薦基金的持股比例顯示方式\n",
    "\n",
    "def go():\n",
    "    clean_csv()\n",
    "    if not fetch_fund_class(): return\n",
    "    merge_files()\n",
    "    recomm = suggesting(sugg_type)\n",
    "    display(recomm)\n",
    "    \n",
    "go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80817e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
